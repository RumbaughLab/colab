{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RumbaughLab_psyTrack.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bUcvebn-BE5h",
        "MVTpgUuvCsg7"
      ],
      "authorship_tag": "ABX9TyP2+b6jiAo4TK+idqXD00Dv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RumbaughLab/colab/blob/main/RumbaughLab_psyTrack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# _Implementation of psyTrack for Rumbaugh Lab_\n",
        "## Figure Generator\n",
        "\n",
        "relevant to:\n",
        "1. Cris Creson\n",
        "2. Sheldon Michaelson\n",
        "3. Randy Golvin\n",
        "4. Tom Vaissiere\n",
        "\n",
        "\n",
        "_(v1.0, last updated January, 26, 2022)_\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3cl2R3bwztnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will attempt at the implementation of psyTrack on WDIL data and especially the WDIL dataset WDIL0007 which are located in a shared folder.\n",
        "\n",
        "Important note: modification of the inuputs should enable analysis of other WDIL dataset\n",
        "\n",
        "Several additional layres can be incorporated like:\n",
        "\n",
        "\n",
        "1.   Stimulus intensities\n",
        "2.   Number of lick in specific interval\n",
        "3.   pick pupil diameter\n",
        "4.   etc.\n",
        "\n",
        "References:\n",
        "\n",
        "\n",
        "*   [psyTrack](https://github.com/nicholas-roy/psytrack)\n",
        "*   [paper](<https://www.cell.com/neuron/fulltext/S0896-6273(20)30963-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627320309636%3Fshowall%3Dtrue>) and [colab](https://tinyurl.com/PsyTrack-colab)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QhY6nN-t0lTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary setup\n",
        "\n",
        "Libraries listed below will need to be install.\n",
        "In the original notebook the useage of oneibl was problematic for the first part of the paper was problematic. Those libraries and code focus mostly on implementation on the Rumbaugh lab data for comparison with the original colab see [here](https://tinyurl.com/PsyTrack-colab)"
      ],
      "metadata": {
        "id": "bUcvebn-BE5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import copy\n",
        "import path\n",
        "import sys\n",
        "\n",
        "# Install then import PsyTrack\n",
        "!pip install psytrack==2.0\n",
        "import psytrack as psy\n",
        "\n",
        "# Set save path for all figures, decide whether to save permanently\n",
        "SPATH = \"Figures/\"\n",
        "!mkdir -p \"{SPATH}\"\n",
        "\n",
        "# Set matplotlib defaults for making files consistent in Illustrator\n",
        "colors = psy.COLORS\n",
        "zorder = psy.ZORDER\n",
        "plt.rcParams['figure.dpi'] = 140\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['savefig.facecolor'] = (1,1,1,0)\n",
        "plt.rcParams['savefig.bbox'] = \"tight\"\n",
        "plt.rcParams['font.size'] = 10\n",
        "# plt.rcParams['font.family'] = 'sans-serif'     # not available in Colab\n",
        "# plt.rcParams['font.sans-serif'] = 'Helvetica'  # not available in Colab\n",
        "plt.rcParams['pdf.fonttype'] = 42\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "mnEVKaVJCbn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom functions"
      ],
      "metadata": {
        "id": "MVTpgUuvCsg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatWDILfile(path):\n",
        "    '''\n",
        "    Function to concatenate all the wdil file into one \n",
        "    to be able to run psytrack\n",
        "\n",
        "    Args:\n",
        "    path (str): with all the files \n",
        "    '''\n",
        "\n",
        "    allFiles = set(glob.glob(path+'/**/*.xlsx', recursive=True)) # get all the excel file in folder\n",
        "    settingFiles = set(glob.glob(path+'/**/settings.xlsx', recursive = True)) # get all the settings file\n",
        "\n",
        "    wdilFiles = allFiles - settingFiles # exclude the settings files\n",
        "    wdilFiles = list(wdilFiles) # convert the set to a list\n",
        "\n",
        "    print('alllFiles: ', len(allFiles), ' wdilFiles: ', len(wdilFiles))\n",
        "    print(wdilFiles)\n",
        "\n",
        "    # important to sort the list to obtain proper sequence \n",
        "    wdilFiles.sort()\n",
        "\n",
        "    allDat = [] # create an empty object to \n",
        "    sID = []\n",
        "    \n",
        "    for i in wdilFiles:\n",
        "        # print(i)\n",
        "        tmp = pd.read_excel(i) # read excel file\n",
        "\n",
        "        ## section to check with previous id and assign absolute order number\n",
        "        tmpsID = i.split(os.sep)[-3]\n",
        "        if tmpsID == sID:\n",
        "            # print('same')\n",
        "            k += 1\n",
        "        else:\n",
        "            k=0\n",
        "        # print(k)\n",
        "\n",
        "\n",
        "        sID = i.split(os.sep)[-3] # add a column with the id\n",
        "        sessionDate = i.split(os.sep)[-2]\n",
        "        tmp['sID'] = sID\n",
        "        tmp['sessionDate'] = sessionDate\n",
        "        tmp['session'] = k\n",
        "        # absSession = # obtain the absolute session number\n",
        "\n",
        "        allDat.append(tmp)\n",
        "    allDat = pd.concat(allDat)\n",
        "\n",
        "    return allDat\n",
        "\n",
        "def codingDatFile(allDat):\n",
        "    '''\n",
        "    Function to code all the wdil file into one \n",
        "    to be able to run psytrack\n",
        "\n",
        "    Args:\n",
        "    allDat\n",
        "    '''\n",
        "\n",
        "    allDat['choice'] = allDat['Lick?']\n",
        "    allDat = allDat.rename(columns={'Trial#':'trial'})\n",
        "    ## establish what are the hit \n",
        "    ## in this case the establishment of hit correspond to true hit:\n",
        "    ##      lick and was a Go # if Go=1 and Correct =1 --> CorrectCat ==2 and is a hit\n",
        "    ## as well as correct rejection:\n",
        "    ##      with held and was a no Go # if Go=0 and Correct =0 --> CorrectCat ==0 and is a hit\n",
        "    allDat['CorrectCat']  = allDat['choice'] + allDat['Correct?'] \n",
        "    allDat['hit'] = np.where((allDat['CorrectCat']==2) | (allDat['CorrectCat']==0),1,0)\n",
        "\n",
        "def getRat(subject, first=20000, cutoff=50):\n",
        "\n",
        "    df = RAT_DF[RAT_DF['subject_id']==subject]  # restrict dataset to single subject\n",
        "    df = df[:first]  # restrict to \"first\" trials of data\n",
        "    # remove sessions with fewer than \"cutoff\" valid trials\n",
        "    df = df.groupby('session').filter(lambda x: len(x) >= cutoff)   \n",
        "\n",
        "    # Normalize the stimuli to standard normal\n",
        "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
        "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
        "    \n",
        "    # Determine which trials do not have a valid previous trial (mistrial or session boundary)\n",
        "    t = np.array(df[\"trial\"])\n",
        "    prior = ((t[1:] - t[:-1]) == 1).astype(int)\n",
        "    prior = np.hstack(([0], prior))\n",
        "\n",
        "    # Calculate previous average tone value\n",
        "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
        "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
        "    s_avg = np.hstack(([0], s_avg))\n",
        "    s_avg = s_avg * prior  # for trials without a valid previous trial, set to 0\n",
        "\n",
        "    # Calculate previous correct answer\n",
        "    h = (df[\"correct_side\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
        "    h = np.hstack(([0], h))\n",
        "    h = h * prior  # for trials without a valid previous trial, set to 0\n",
        "    \n",
        "    # Calculate previous choice\n",
        "    c = (df[\"choice\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
        "    c = np.hstack(([0], c))\n",
        "    c = c * prior  # for trials without a valid previous trial, set to 0\n",
        "    \n",
        "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
        "                  s_b = np.array(s_b)[:, None],\n",
        "                  s_avg = np.array(s_avg)[:, None],\n",
        "                  h = np.array(h)[:, None],\n",
        "                  c = np.array(c)[:, None])\n",
        "\n",
        "    dat = dict(\n",
        "        subject = subject,\n",
        "        inputs = inputs,\n",
        "        s_a = np.array(df['s_a']),\n",
        "        s_b = np.array(df['s_b']),\n",
        "        correct = np.array(df['hit']),\n",
        "        answer = np.array(df['correct_side']),\n",
        "        y = np.array(df['choice']),\n",
        "        dayLength=np.array(df.groupby(['session']).size()),\n",
        "    )\n",
        "    return dat\n",
        "\n",
        "def convertToDict(allDat, subject, first=20000, cutoff=50):\n",
        "\n",
        "    '''\n",
        "    equivalent to the function getRat from the paper see above and here https://tinyurl.com/PsyTrack-colab\n",
        "    '''\n",
        "\n",
        "    df = allDat[allDat['sID']==subject]  # restrict dataset to single subject\n",
        "    df = df[:first] # restrict to \"first\" trials of data\n",
        "    # # remove sessions with fewer than \"cutoff\" valid trials\n",
        "    # df = df.groupby('session').filter(lambda x: len(x) >= cutoff)   \n",
        "\n",
        "    # Determine which trials do not have a valid previous trial (mistrial or session boundary)\n",
        "    t = np.array(df[\"trial\"])\n",
        "    prior = ((t[1:] - t[:-1]) == 1).astype(int)\n",
        "    prior = np.hstack(([0], prior))\n",
        "\n",
        "    # Calculate previous correct answer\n",
        "    h = (df[\"Correct?\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
        "    h = np.hstack(([0], h))\n",
        "    h = h * prior  # for trials without a valid previous trial, set to 0\n",
        "    \n",
        "    # Calculate previous choice\n",
        "    c = (df[\"choice\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
        "    c = np.hstack(([0], c))\n",
        "    c = c * prior  # for trials without a valid previous trial, set to 0\n",
        "    \n",
        "    # note here that it could be useful to have different stimulus values \n",
        "    inputs = dict(stim = np.array(df['Go/NoGo'])[:, None], \n",
        "                  h = np.array(h)[:, None],\n",
        "                  c = np.array(c)[:, None])\n",
        "\n",
        "    dat = dict(\n",
        "        subject = subject,\n",
        "        inputs = inputs,\n",
        "        stim = np.array(df['Go/NoGo']), # correspond to the go/noGo stim\n",
        "        correct = np.array(df['hit']), # hit correspond to hit and correct rejection\n",
        "        answer = np.array(df['Correct?']), #this is the answer \n",
        "        y = np.array(df['choice']), #this correspond to the Lick\n",
        "        dayLength=np.array(df.groupby(['session']).size()),\n",
        "    )\n",
        "\n",
        "    return dat\n",
        "\n",
        "def tpath(mypath, shareDrive = 'Y'):\n",
        "    '''\n",
        "    path conversion to switch form linux to windows platform with define drive\n",
        "    Args:\n",
        "    mypath (str): path of the file of interest\n",
        "    shareDrive (str): windows letter of the shared folder\n",
        "    '''\n",
        "    if sys.platform == 'linux':\n",
        "        myRoot = '/run/user/1000/gvfs/smb-share:server=ishtar,share=millerrumbaughlab'\n",
        "    else:\n",
        "        myRoot = shareDrive+':'\n",
        "\n",
        "    newpath = myRoot+os.sep+mypath\n",
        "\n",
        "    return newpath\n"
      ],
      "metadata": {
        "id": "yzI1Ew69CwpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WDIL data"
      ],
      "metadata": {
        "id": "sA4RZwl9CzoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YCatw3F2DJGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}